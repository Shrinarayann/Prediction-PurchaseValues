{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8becb4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "\n",
      "--- Preprocessing Data and Validating Model ---\n",
      "Fitting preprocessor and transforming data...\n",
      "Training model and recording validation performance...\n",
      "Validation complete. Best iteration found at: 2499 with RMSE: 0.7481\n",
      "\n",
      "--- Training Final Model on ALL Data ---\n",
      "Training final pipeline for 2499 rounds...\n",
      "\n",
      "--- Generating Final Kaggle Submission ---\n",
      "✅ Submission file 'submission.csv' created successfully.\n",
      "Top 5 rows of submission file:\n",
      "   id  purchaseValue\n",
      "0   0   2.445515e+07\n",
      "1   1   1.609249e+05\n",
      "2   2   1.413633e+03\n",
      "3   3   5.831444e+04\n",
      "4   4   2.876357e+04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 1: FEATURE ENGINEERING & PREPROCESSING CLASSES (UNCHANGED)\n",
    "# ==============================================================================\n",
    "\n",
    "class AdvancedFeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['date'] = pd.to_datetime(X_copy['date'], format='%Y%m%d')\n",
    "        X_copy['sessionYear'] = X_copy['date'].dt.year\n",
    "        X_copy['sessionMonth'] = X_copy['date'].dt.month\n",
    "        X_copy['sessionDayOfWeek'] = X_copy['date'].dt.dayofweek\n",
    "        X_copy['sessionHour'] = pd.to_datetime(X_copy['sessionStart'], unit='s').dt.hour\n",
    "        X_copy['is_weekend'] = (X_copy['sessionDayOfWeek'] >= 5).astype(int)\n",
    "        X_copy['month_day_interaction'] = X_copy['sessionMonth'].astype(str) + '_' + X_copy['sessionDayOfWeek'].astype(str)\n",
    "        X_copy['browser_os_interaction'] = X_copy['browser'].astype(str) + '_' + X_copy['os'].astype(str)\n",
    "        X_copy['hits_per_pageview'] = X_copy['totalHits'] / (X_copy['pageViews'].fillna(0) + 1e-6)\n",
    "        X_copy['ad_page_binned'] = X_copy['trafficSource.adwordsClickInfo.page'].apply(lambda p: 1 if p == 1.0 else (2 if pd.notna(p) else 0))\n",
    "        cols_to_drop = ['date', 'sessionStart', 'userId', 'sessionId', 'trafficSource.adwordsClickInfo.page']\n",
    "        X_copy = X_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "        return X_copy\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns; self.mappings_ = {}; self.global_mean_ = 0\n",
    "    def fit(self, X, y):\n",
    "        X_fit, y_fit = X.copy(), y.copy()\n",
    "        self.global_mean_ = np.mean(y_fit)\n",
    "        for col in self.columns:\n",
    "            X_fit[col] = X_fit[col].fillna('missing')\n",
    "            self.mappings_[col] = y_fit.groupby(X_fit[col]).mean().to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transform = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_transform[col] = X_transform[col].fillna('missing')\n",
    "            X_transform[col] = X_transform[col].map(self.mappings_[col]).fillna(self.global_mean_)\n",
    "        return X_transform\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: DATA PREPARATION\n",
    "# ==============================================================================\n",
    "TRAIN_FILE_PATH = './dataset/train_data.csv'\n",
    "TEST_FILE_PATH = './dataset/test_data.csv'\n",
    "SUBMISSION_FILE_PATH = 'submission.csv'\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "df = pd.read_csv(TRAIN_FILE_PATH, dtype={'userId': 'str', 'sessionId': 'str'})\n",
    "one_value_cols = [col for col in df.columns if df[col].nunique(dropna=False) == 1]\n",
    "df = df.drop(columns=one_value_cols)\n",
    "\n",
    "df['purchaseValue'] = df['purchaseValue'].fillna(0) / 1e6\n",
    "df['log_purchaseValue'] = np.log1p(df['purchaseValue'])\n",
    "\n",
    "X = df.drop(columns=['purchaseValue', 'log_purchaseValue'])\n",
    "y = df[['log_purchaseValue', 'purchaseValue']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 3: PREPROCESSING & BULLETPROOF VALIDATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preprocessing Data and Validating Model ---\")\n",
    "\n",
    "temp_engineered_df = AdvancedFeatureEngineering().fit_transform(X)\n",
    "numerical_cols = ['sessionNumber', 'pageViews', 'totalHits', 'sessionYear', 'sessionMonth', 'sessionDayOfWeek', 'sessionHour', 'hits_per_pageview', 'ad_page_binned', 'is_weekend']\n",
    "categorical_cols = [col for col in temp_engineered_df.columns if col not in numerical_cols]\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('engineering', AdvancedFeatureEngineering()),\n",
    "    ('col_transformer', ColumnTransformer([\n",
    "        ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "        ('cat', TargetEncoder(columns=categorical_cols), categorical_cols)\n",
    "    ]))\n",
    "])\n",
    "\n",
    "print(\"Fitting preprocessor and transforming data...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train, y_train['log_purchaseValue'])\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "print(\"Training model and recording validation performance...\")\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=2500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# *** THE FIX: We train for all rounds and find the best one AFTERWARDS ***\n",
    "# This avoids any problematic keyword arguments in .fit()\n",
    "model.fit(X_train_processed, y_train['log_purchaseValue'],\n",
    "          eval_set=[(X_val_processed, y_val['log_purchaseValue'])],\n",
    "          verbose=False) # verbose=False keeps the log clean\n",
    "\n",
    "# Find the best iteration by looking at the model's history\n",
    "results = model.evals_result()\n",
    "# The history is in a nested dict: {'validation_0': {'rmse': [val1, val2, ...]}}\n",
    "validation_rmse = results['validation_0']['rmse']\n",
    "best_iteration = np.argmin(validation_rmse) + 1 # +1 because list is 0-indexed\n",
    "print(f\"Validation complete. Best iteration found at: {best_iteration} with RMSE: {validation_rmse[best_iteration-1]:.4f}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 4: FINAL MODEL TRAINING AND SUBMISSION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Training Final Model on ALL Data ---\")\n",
    "\n",
    "# Define final model parameters using the best iteration we found\n",
    "final_model_params = model.get_params()\n",
    "final_model_params['n_estimators'] = best_iteration\n",
    "\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(**final_model_params))\n",
    "])\n",
    "\n",
    "print(f\"Training final pipeline for {best_iteration} rounds...\")\n",
    "final_pipeline.fit(X, y['log_purchaseValue'])\n",
    "\n",
    "print(\"\\n--- Generating Final Kaggle Submission ---\")\n",
    "try:\n",
    "    kaggle_test_df = pd.read_csv(TEST_FILE_PATH, dtype={'userId': 'str', 'sessionId': 'str'})\n",
    "    kaggle_test_df = kaggle_test_df.drop(columns=[c for c in one_value_cols if c in kaggle_test_df.columns], errors='ignore')\n",
    "\n",
    "    final_log_pred = final_pipeline.predict(kaggle_test_df)\n",
    "    \n",
    "    final_value_pred = np.expm1(final_log_pred)\n",
    "    final_value_pred[final_value_pred < 0] = 0\n",
    "    final_predictions_scaled = final_value_pred * 1e6\n",
    "    \n",
    "    submission_df = pd.DataFrame({'id': kaggle_test_df.index, 'purchaseValue': final_predictions_scaled})\n",
    "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "    \n",
    "    print(f\"✅ Submission file '{SUBMISSION_FILE_PATH}' created successfully.\")\n",
    "    print(\"Top 5 rows of submission file:\")\n",
    "    print(submission_df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nKaggle '{TEST_FILE_PATH}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during submission generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087a0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
