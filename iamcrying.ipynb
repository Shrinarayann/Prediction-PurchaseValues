{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7608cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:15:28,711] A new study created in memory with name: no-name-41972966-7cab-470e-b0d7-ba93600ca3b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified 13 potential numerical features.\n",
      "Identified 38 potential categorical features.\n",
      "\n",
      "--- Tuning Regressor with Optuna (30 trials) using LEAK-FREE CV ---\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.40970\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.44570\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.41829\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:15:50,868] Trial 0 finished with value: 1.4218815558037812 and parameters: {'n_estimators': 1200, 'learning_rate': 0.04195599971217711, 'max_depth': 9, 'subsample': 0.8538678095370361, 'colsample_bytree': 0.8724003816032452, 'gamma': 3.963598082497761, 'lambda': 5.264359622322329, 'alpha': 0.35225822524924344, 'smoothing': 19}. Best is trial 0 with value: 1.4218815558037812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.41384\n",
      "  Trial Mean RMSE: 1.42188\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33851\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.34275\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.34941\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:16:13,475] Trial 1 finished with value: 1.3367521185024154 and parameters: {'n_estimators': 1500, 'learning_rate': 0.010579160198661874, 'max_depth': 7, 'subsample': 0.8814832819709645, 'colsample_bytree': 0.7062772819581706, 'gamma': 3.114669885623644, 'lambda': 2.766024822102694, 'alpha': 6.146592436887045, 'smoothing': 17}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31634\n",
      "  Trial Mean RMSE: 1.33675\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.46054\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.49089\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.46619\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:16:31,608] Trial 2 finished with value: 1.4773350043115283 and parameters: {'n_estimators': 1100, 'learning_rate': 0.04741139806781882, 'max_depth': 5, 'subsample': 0.7909419373955434, 'colsample_bytree': 0.9655051456648853, 'gamma': 2.589993236444341, 'lambda': 1.8269636148759114, 'alpha': 1.0782178093395167, 'smoothing': 10}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.49171\n",
      "  Trial Mean RMSE: 1.47734\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.41078\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.38381\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.38517\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:16:49,241] Trial 3 finished with value: 1.3873755298525423 and parameters: {'n_estimators': 800, 'learning_rate': 0.026619748374141754, 'max_depth': 7, 'subsample': 0.9117604772745982, 'colsample_bytree': 0.8042862468265644, 'gamma': 1.584525179529967, 'lambda': 5.189083907090946, 'alpha': 9.669486985812823, 'smoothing': 17}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.36974\n",
      "  Trial Mean RMSE: 1.38738\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.48148\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.49570\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.48566\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:17:05,621] Trial 4 finished with value: 1.4904065017504546 and parameters: {'n_estimators': 500, 'learning_rate': 0.028176283489031843, 'max_depth': 9, 'subsample': 0.7172216386351448, 'colsample_bytree': 0.9053294557044307, 'gamma': 0.5921399319752096, 'lambda': 1.7377825256444945, 'alpha': 5.583035608899251, 'smoothing': 19}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.49879\n",
      "  Trial Mean RMSE: 1.49041\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.42931\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.44838\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.42160\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:17:24,521] Trial 5 finished with value: 1.4381600410292341 and parameters: {'n_estimators': 1100, 'learning_rate': 0.03726843126016152, 'max_depth': 7, 'subsample': 0.8324985275660698, 'colsample_bytree': 0.8783890610189111, 'gamma': 1.8822531216345073, 'lambda': 2.9077464736129706, 'alpha': 2.0784149057673886, 'smoothing': 15}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.45335\n",
      "  Trial Mean RMSE: 1.43816\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.44373\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.46446\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.45092\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:17:42,006] Trial 6 finished with value: 1.45983792166445 and parameters: {'n_estimators': 900, 'learning_rate': 0.04652062753650455, 'max_depth': 8, 'subsample': 0.8989022470733623, 'colsample_bytree': 0.9519234813640917, 'gamma': 1.3650430479929032, 'lambda': 2.1350356166666757, 'alpha': 7.748783227936427, 'smoothing': 9}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.48025\n",
      "  Trial Mean RMSE: 1.45984\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33919\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.36254\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36307\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:18:04,763] Trial 7 finished with value: 1.3493893606570975 and parameters: {'n_estimators': 1700, 'learning_rate': 0.019696347714259477, 'max_depth': 6, 'subsample': 0.9070234570197794, 'colsample_bytree': 0.8419863436819892, 'gamma': 3.5520852855098104, 'lambda': 3.415685541837198, 'alpha': 4.61309595848039, 'smoothing': 9}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33276\n",
      "  Trial Mean RMSE: 1.34939\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.46360\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.48782\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.46458\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:18:20,658] Trial 8 finished with value: 1.4756441786095649 and parameters: {'n_estimators': 500, 'learning_rate': 0.0391908253631572, 'max_depth': 8, 'subsample': 0.939645002893345, 'colsample_bytree': 0.9878562582196669, 'gamma': 2.829825697656387, 'lambda': 6.583855913463353, 'alpha': 0.680998534891023, 'smoothing': 18}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.48657\n",
      "  Trial Mean RMSE: 1.47564\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.42735\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.44495\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.43786\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:18:41,441] Trial 9 finished with value: 1.4383103395906658 and parameters: {'n_estimators': 1200, 'learning_rate': 0.012341162654139048, 'max_depth': 5, 'subsample': 0.8182158571085357, 'colsample_bytree': 0.9574796612059007, 'gamma': 3.0166832706196405, 'lambda': 1.239802385003242, 'alpha': 0.8106038862273035, 'smoothing': 19}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.44308\n",
      "  Trial Mean RMSE: 1.43831\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.34329\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35337\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36065\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:19:06,431] Trial 10 finished with value: 1.3452803795432975 and parameters: {'n_estimators': 1700, 'learning_rate': 0.010024473173437697, 'max_depth': 12, 'subsample': 0.9857415616142366, 'colsample_bytree': 0.7085028045872818, 'gamma': 4.986901677906902, 'lambda': 9.664201772955641, 'alpha': 4.743106677244759, 'smoothing': 13}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.32381\n",
      "  Trial Mean RMSE: 1.34528\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33754\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35955\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35330\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:19:30,577] Trial 11 finished with value: 1.3458342329143513 and parameters: {'n_estimators': 1700, 'learning_rate': 0.010029596986505183, 'max_depth': 12, 'subsample': 0.984924373142753, 'colsample_bytree': 0.7000292677314683, 'gamma': 4.886335230320132, 'lambda': 8.913593181853683, 'alpha': 4.875299249895549, 'smoothing': 13}. Best is trial 1 with value: 1.3367521185024154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33295\n",
      "  Trial Mean RMSE: 1.34583\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32981\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35363\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.33118\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:19:54,754] Trial 12 finished with value: 1.3326037693800346 and parameters: {'n_estimators': 2000, 'learning_rate': 0.01540385788177947, 'max_depth': 12, 'subsample': 0.9657669160377108, 'colsample_bytree': 0.7075748711332545, 'gamma': 4.967652948812618, 'lambda': 3.367077192685916, 'alpha': 6.435086012946778, 'smoothing': 5}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31581\n",
      "  Trial Mean RMSE: 1.33260\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33845\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.36616\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36818\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:20:19,042] Trial 13 finished with value: 1.352050133265718 and parameters: {'n_estimators': 2000, 'learning_rate': 0.015432229578158613, 'max_depth': 10, 'subsample': 0.959145813370515, 'colsample_bytree': 0.7591252033876367, 'gamma': 4.105100066094979, 'lambda': 3.2033608087893475, 'alpha': 7.048991366171288, 'smoothing': 5}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33541\n",
      "  Trial Mean RMSE: 1.35205\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.34416\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35835\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36640\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:20:43,158] Trial 14 finished with value: 1.3509941163104573 and parameters: {'n_estimators': 2000, 'learning_rate': 0.015517899148917727, 'max_depth': 11, 'subsample': 0.8705395062357159, 'colsample_bytree': 0.7459361855568266, 'gamma': 4.235168371501993, 'lambda': 4.337357349705002, 'alpha': 7.14329469781197, 'smoothing': 5}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33507\n",
      "  Trial Mean RMSE: 1.35099\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.47785\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.45969\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.49534\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:21:21,910] Trial 15 finished with value: 1.484842389698295 and parameters: {'n_estimators': 1500, 'learning_rate': 0.014069628761234066, 'max_depth': 10, 'subsample': 0.7764736713374789, 'colsample_bytree': 0.7774477406154716, 'gamma': 0.005544867473307846, 'lambda': 2.5676283606448087, 'alpha': 3.611254034593647, 'smoothing': 16}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.50648\n",
      "  Trial Mean RMSE: 1.48484\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.35836\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.36068\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36085\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:21:43,141] Trial 16 finished with value: 1.353381562669286 and parameters: {'n_estimators': 1500, 'learning_rate': 0.018571827936967548, 'max_depth': 7, 'subsample': 0.9420400513573571, 'colsample_bytree': 0.7294552370014072, 'gamma': 3.4504476622378735, 'lambda': 1.1082547403421585, 'alpha': 8.90393933152965, 'smoothing': 7}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33364\n",
      "  Trial Mean RMSE: 1.35338\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.38497\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.37523\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.38223\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:22:06,004] Trial 17 finished with value: 1.3760327315777041 and parameters: {'n_estimators': 1500, 'learning_rate': 0.013460244435377773, 'max_depth': 11, 'subsample': 0.8796160507473809, 'colsample_bytree': 0.8072597852400534, 'gamma': 2.1182589185239378, 'lambda': 3.9977261029809483, 'alpha': 6.246790185463784, 'smoothing': 11}. Best is trial 12 with value: 1.3326037693800346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.36170\n",
      "  Trial Mean RMSE: 1.37603\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32692\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.34114\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.32801\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:22:33,199] Trial 18 finished with value: 1.3264493830394408 and parameters: {'n_estimators': 1900, 'learning_rate': 0.011164649797353439, 'max_depth': 6, 'subsample': 0.7061146990552216, 'colsample_bytree': 0.7821786922926288, 'gamma': 4.560588523006475, 'lambda': 2.388590274590411, 'alpha': 3.6949247191996317, 'smoothing': 15}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.30972\n",
      "  Trial Mean RMSE: 1.32645\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.31888\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35795\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35101\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:22:57,186] Trial 19 finished with value: 1.336560724189468 and parameters: {'n_estimators': 1900, 'learning_rate': 0.019764509175658085, 'max_depth': 6, 'subsample': 0.7090556485514026, 'colsample_bytree': 0.7918676471388736, 'gamma': 4.652743530751559, 'lambda': 1.4640559165846607, 'alpha': 2.480821118040569, 'smoothing': 14}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31841\n",
      "  Trial Mean RMSE: 1.33656\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32938\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.34175\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.34291\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:23:21,474] Trial 20 finished with value: 1.33148119979762 and parameters: {'n_estimators': 1800, 'learning_rate': 0.011904103421767004, 'max_depth': 10, 'subsample': 0.7371134868752788, 'colsample_bytree': 0.8287565765676573, 'gamma': 4.414502498976418, 'lambda': 2.4785051368941984, 'alpha': 3.5373805191999153, 'smoothing': 7}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31188\n",
      "  Trial Mean RMSE: 1.33148\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32768\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.34885\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35212\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:23:45,844] Trial 21 finished with value: 1.3351075774126058 and parameters: {'n_estimators': 1800, 'learning_rate': 0.012046174844108836, 'max_depth': 11, 'subsample': 0.745794031886441, 'colsample_bytree': 0.8399842188835014, 'gamma': 4.546439405328126, 'lambda': 2.3742874035374615, 'alpha': 3.498327079123417, 'smoothing': 7}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31178\n",
      "  Trial Mean RMSE: 1.33511\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.35105\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.36051\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35954\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:24:12,316] Trial 22 finished with value: 1.3519998094859789 and parameters: {'n_estimators': 1900, 'learning_rate': 0.016874784348739444, 'max_depth': 10, 'subsample': 0.7508678957479391, 'colsample_bytree': 0.8227194077531431, 'gamma': 3.6393531134951163, 'lambda': 1.940792706785958, 'alpha': 3.6112042762641967, 'smoothing': 7}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33690\n",
      "  Trial Mean RMSE: 1.35200\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33256\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35582\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35283\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:24:37,823] Trial 23 finished with value: 1.341474830423481 and parameters: {'n_estimators': 2000, 'learning_rate': 0.01131370324098339, 'max_depth': 12, 'subsample': 0.7016543333143395, 'colsample_bytree': 0.7545822974941401, 'gamma': 4.489918915792743, 'lambda': 3.7420200551524125, 'alpha': 2.49896351947133, 'smoothing': 6}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.32469\n",
      "  Trial Mean RMSE: 1.34147\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32632\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35481\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.33907\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:25:02,585] Trial 24 finished with value: 1.3336448868994817 and parameters: {'n_estimators': 1800, 'learning_rate': 0.012939741175385254, 'max_depth': 9, 'subsample': 0.7366286850214929, 'colsample_bytree': 0.7729223588871575, 'gamma': 4.01556556877727, 'lambda': 1.4463534932043354, 'alpha': 4.051540363363973, 'smoothing': 11}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31437\n",
      "  Trial Mean RMSE: 1.33364\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.33774\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.36144\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36755\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:25:25,135] Trial 25 finished with value: 1.346431982071436 and parameters: {'n_estimators': 1600, 'learning_rate': 0.014857217277014518, 'max_depth': 10, 'subsample': 0.7800127427651342, 'colsample_bytree': 0.732748921772175, 'gamma': 4.427104797901458, 'lambda': 2.2496000616519427, 'alpha': 1.7460589486817395, 'smoothing': 8}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.31900\n",
      "  Trial Mean RMSE: 1.34643\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.40683\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.41229\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.41002\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:25:48,499] Trial 26 finished with value: 1.4100018750233858 and parameters: {'n_estimators': 1900, 'learning_rate': 0.02249599059431238, 'max_depth': 11, 'subsample': 0.8049631290012789, 'colsample_bytree': 0.9033858658768414, 'gamma': 4.991277747721752, 'lambda': 4.456553477296799, 'alpha': 6.05233110892186, 'smoothing': 5}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.41086\n",
      "  Trial Mean RMSE: 1.41000\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.34418\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.35866\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35841\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:26:11,477] Trial 27 finished with value: 1.349127164914503 and parameters: {'n_estimators': 1400, 'learning_rate': 0.011490661186744829, 'max_depth': 6, 'subsample': 0.7283825876019323, 'colsample_bytree': 0.8212084067677775, 'gamma': 3.7788366941846494, 'lambda': 3.0381612166347054, 'alpha': 8.118770614810177, 'smoothing': 15}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.33526\n",
      "  Trial Mean RMSE: 1.34913\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.32841\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.34806\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.35662\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:26:35,263] Trial 28 finished with value: 1.3390586935320696 and parameters: {'n_estimators': 1800, 'learning_rate': 0.017636993733221595, 'max_depth': 8, 'subsample': 0.7699437342408489, 'colsample_bytree': 0.8588921661771642, 'gamma': 4.6618070837453045, 'lambda': 1.6283736584791124, 'alpha': 2.91528470370736, 'smoothing': 6}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.32314\n",
      "  Trial Mean RMSE: 1.33906\n",
      "\n",
      "  --- Fold 1/4 ---\n",
      "    Fold 1 RMSE: 1.36638\n",
      "  --- Fold 2/4 ---\n",
      "    Fold 2 RMSE: 1.37946\n",
      "  --- Fold 3/4 ---\n",
      "    Fold 3 RMSE: 1.36973\n",
      "  --- Fold 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 20:26:56,176] Trial 29 finished with value: 1.3644570477276092 and parameters: {'n_estimators': 1300, 'learning_rate': 0.02289427641126675, 'max_depth': 9, 'subsample': 0.8427056425411141, 'colsample_bytree': 0.7826022955412402, 'gamma': 4.174132445259895, 'lambda': 5.248461355615132, 'alpha': 4.2450241885580695, 'smoothing': 10}. Best is trial 18 with value: 1.3264493830394408.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4 RMSE: 1.34226\n",
      "  Trial Mean RMSE: 1.36446\n",
      "\n",
      "\n",
      "Best trial:\n",
      "  Value (RMSE): 1.32645\n",
      "  Params: \n",
      "    n_estimators: 1900\n",
      "    learning_rate: 0.011164649797353439\n",
      "    max_depth: 6\n",
      "    subsample: 0.7061146990552216\n",
      "    colsample_bytree: 0.7821786922926288\n",
      "    gamma: 4.560588523006475\n",
      "    lambda: 2.388590274590411\n",
      "    alpha: 3.6949247191996317\n",
      "    smoothing: 15\n",
      "\n",
      "--- Training Final Model with Best Parameters on ALL Data ---\n",
      "Final model trained successfully.\n",
      "\n",
      "--- Generating Final Kaggle Submission ---\n",
      "Submission file 'submission_robust_model.csv' created successfully.\n",
      "   ID  purchaseValue\n",
      "0   0   60122.062500\n",
      "1   1    2306.391602\n",
      "2   2    2306.391602\n",
      "3   3   16237.957031\n",
      "4   4    2306.391602\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# VERSION: Robust & Leak-Free Model\n",
    "# This version implements a leak-proof cross-validation scheme for reliable\n",
    "# hyperparameter tuning and trains a powerful final model.\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# --- Define File Paths ---\n",
    "TRAIN_FILE_PATH = '/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/train_data.csv'\n",
    "TEST_FILE_PATH = '/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/test_data.csv'\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 1: FEATURE ENGINEERING & PREPROCESSING CLASSES (Largely Unchanged)\n",
    "# ==============================================================================\n",
    "\n",
    "class AdvancedFeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Creates time-based and interaction features from session-level data.\"\"\"\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['date'] = pd.to_datetime(X_copy['date'], format='%Y%m%d')\n",
    "        X_copy['sessionYear'] = X_copy['date'].dt.year\n",
    "        X_copy['sessionMonth'] = X_copy['date'].dt.month\n",
    "        X_copy['sessionDayOfWeek'] = X_copy['date'].dt.dayofweek\n",
    "        X_copy['sessionHour'] = pd.to_datetime(X_copy['sessionStart'], unit='s').dt.hour\n",
    "        X_copy['is_weekend'] = (X_copy['sessionDayOfWeek'] >= 5).astype(int)\n",
    "        X_copy['month_day_interaction'] = X_copy['sessionMonth'].astype(str) + '_' + X_copy['sessionDayOfWeek'].astype(str)\n",
    "        X_copy['browser_os_interaction'] = X_copy['browser'].astype(str) + '_' + X_copy['os'].astype(str)\n",
    "        X_copy['geo_channel_interaction'] = X_copy['geoNetwork.continent'].astype(str) + '_' + X_copy['userChannel'].astype(str)\n",
    "        X_copy['device_channel_interaction'] = X_copy['deviceType'].astype(str) + '_' + X_copy['userChannel'].astype(str)\n",
    "        X_copy['hits_per_pageview'] = X_copy['totalHits'] / (X_copy['pageViews'].replace(0, 1)) # Avoid division by zero\n",
    "        X_copy['ad_page_binned'] = X_copy['trafficSource.adwordsClickInfo.page'].apply(lambda p: 1 if p == 1.0 else (2 if pd.notna(p) else 0))\n",
    "        cols_to_drop = ['date', 'sessionStart', 'sessionId', 'trafficSource.adwordsClickInfo.page']\n",
    "        X_copy = X_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "        return X_copy\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Target encodes categorical features with smoothing.\"\"\"\n",
    "    def __init__(self, columns=None, smoothing=10):\n",
    "        self.columns, self.smoothing = columns, smoothing\n",
    "        self.mappings_, self.global_mean_ = {}, 0\n",
    "    def fit(self, X, y):\n",
    "        X_fit, y_fit = X.copy(), y.copy()\n",
    "        self.global_mean_ = np.mean(y_fit)\n",
    "        for col in self.columns:\n",
    "            X_fit[col] = X_fit[col].fillna('missing').astype(str)\n",
    "            agg = y_fit.groupby(X_fit[col]).agg(['mean', 'count'])\n",
    "            smooth_mean = (agg['count'] * agg['mean'] + self.smoothing * self.global_mean_) / (agg['count'] + self.smoothing)\n",
    "            self.mappings_[col] = smooth_mean.to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transform = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_transform[col] = X_transform[col].fillna('missing').astype(str)\n",
    "            X_transform[col] = X_transform[col].map(self.mappings_[col]).fillna(self.global_mean_)\n",
    "        return X_transform\n",
    "\n",
    "def create_user_aggregates(df):\n",
    "    \"\"\"Creates user-level aggregates. Designed to be used on a training fold.\"\"\"\n",
    "    agg = df.groupby('userId').agg(\n",
    "        user_session_count=('sessionId', 'nunique'),\n",
    "        user_total_hits=('totalHits', 'sum'),\n",
    "        user_avg_hits=('totalHits', 'mean'),\n",
    "        user_total_pageviews=('pageViews', 'sum'),\n",
    "        user_avg_pageviews=('pageViews', 'mean'),\n",
    "        user_purchase_count=('made_purchase', 'sum'),\n",
    "        user_total_purchase_value=('purchaseValue', 'sum'),\n",
    "    ).reset_index()\n",
    "    agg['user_conversion_rate'] = agg['user_purchase_count'] / agg['user_session_count']\n",
    "    agg['user_avg_purchase_value'] = agg['user_total_purchase_value'] / (agg['user_purchase_count'] + 1e-6)\n",
    "    return agg\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: DATA LOADING AND INITIAL PREPARATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "df_train = pd.read_csv(TRAIN_FILE_PATH, dtype={'fullVisitorId': 'str', 'sessionId': 'str'})\n",
    "df_test = pd.read_csv(TEST_FILE_PATH, dtype={'fullVisitorId': 'str', 'sessionId': 'str'})\n",
    "\n",
    "# Unify userId column name\n",
    "df_train.rename(columns={'fullVisitorId': 'userId'}, inplace=True)\n",
    "df_test.rename(columns={'fullVisitorId': 'userId'}, inplace=True)\n",
    "\n",
    "# Drop constant columns\n",
    "one_value_cols = [col for col in df_train.columns if df_train[col].nunique(dropna=False) == 1]\n",
    "df_train = df_train.drop(columns=one_value_cols)\n",
    "df_test = df_test.drop(columns=[c for c in one_value_cols if c in df_test.columns], errors='ignore')\n",
    "\n",
    "# Prepare target variable and related columns\n",
    "df_train['purchaseValue'] = df_train['purchaseValue'].fillna(0).astype(float)\n",
    "df_train['made_purchase'] = (df_train['purchaseValue'] > 0).astype(int)\n",
    "df_train['log_purchaseValue'] = np.log1p(df_train['purchaseValue'] / 1e6) # Scale before log\n",
    "\n",
    "# Define features and target\n",
    "X = df_train.drop(columns=['log_purchaseValue'])\n",
    "y = df_train['log_purchaseValue']\n",
    "\n",
    "# Get column names after initial feature engineering\n",
    "temp_engineered_df = AdvancedFeatureEngineering().fit_transform(X)\n",
    "user_level_numerical_cols = [\n",
    "    'user_session_count', 'user_total_hits', 'user_avg_hits', 'user_total_pageviews',\n",
    "    'user_avg_pageviews', 'user_purchase_count', 'user_total_purchase_value',\n",
    "    'user_conversion_rate', 'user_avg_purchase_value'\n",
    "]\n",
    "session_level_numerical_cols = ['sessionNumber', 'pageViews', 'totalHits', 'hits_per_pageview']\n",
    "numerical_cols = session_level_numerical_cols + user_level_numerical_cols\n",
    "categorical_cols = [col for col in temp_engineered_df.columns if col not in numerical_cols and col != 'userId']\n",
    "del temp_engineered_df # Clean up\n",
    "\n",
    "print(f\"\\nIdentified {len(numerical_cols)} potential numerical features.\")\n",
    "print(f\"Identified {len(categorical_cols)} potential categorical features.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 3: ROBUST HYPERPARAMETER TUNING WITH LEAK-FREE CV\n",
    "# ==============================================================================\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 3: ROBUST HYPERPARAMETER TUNING (Corrected)\n",
    "# ==============================================================================\n",
    "\n",
    "def objective(trial, X_data, y_data):\n",
    "    \"\"\"Optuna objective function with a leak-free CV implementation.\"\"\"\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'random_state': 42, 'n_jobs': -1,\n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        \n",
    "        # --- FIX APPLIED HERE ---\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),                               # Removed log=True\n",
    "        'lambda': trial.suggest_float('lambda', 1, 10, log=True),                 # L2 (lambda) can be log-scaled as its lower bound > 0\n",
    "        'alpha': trial.suggest_float('alpha', 0, 10),                             # L1 (alpha) must be linear-scaled to include 0\n",
    "    }\n",
    "\n",
    "    cv = GroupKFold(n_splits=4)\n",
    "    # ... rest of the function remains exactly the same ...\n",
    "    # ...\n",
    "    groups = X_data['userId']\n",
    "    cv_scores = []\n",
    "\n",
    "    # --- THE LEAK-FREE CROSS-VALIDATION LOOP ---\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_data, y_data, groups)):\n",
    "        print(f\"  --- Fold {fold+1}/4 ---\")\n",
    "        X_train, X_val = X_data.iloc[train_idx], X_data.iloc[val_idx]\n",
    "        y_train, y_val = y_data.iloc[train_idx], y_data.iloc[val_idx]\n",
    "\n",
    "        # 1. Create user aggregates ONLY from the training fold's data\n",
    "        # This is the crucial step to prevent data leakage.\n",
    "        user_aggs_fold = create_user_aggregates(X_train)\n",
    "\n",
    "        # 2. Apply advanced feature engineering\n",
    "        afe = AdvancedFeatureEngineering()\n",
    "        X_train_eng = afe.fit_transform(X_train)\n",
    "        X_val_eng = afe.transform(X_val)\n",
    "\n",
    "        # 3. Merge aggregates into the engineered train and validation folds\n",
    "        X_train_final = pd.merge(X_train_eng, user_aggs_fold, on='userId', how='left').fillna(0)\n",
    "        X_val_final = pd.merge(X_val_eng, user_aggs_fold, on='userId', how='left').fillna(0)\n",
    "        \n",
    "        # 4. Define and fit the full preprocessing and model pipeline on the fold\n",
    "        # The TargetEncoder is now correctly fitted only on train data for each fold.\n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "            ('cat', TargetEncoder(columns=categorical_cols, smoothing=trial.suggest_int('smoothing', 5, 20)), categorical_cols)\n",
    "        ], remainder='drop', n_jobs=-1)\n",
    "        \n",
    "        model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', xgb.XGBRegressor(**params))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_train_final, y_train)\n",
    "        preds = model.predict(X_val_final)\n",
    "        \n",
    "        # Clip predictions as log values shouldn't be negative\n",
    "        preds[preds < 0] = 0\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        cv_scores.append(rmse)\n",
    "        print(f\"    Fold {fold+1} RMSE: {rmse:.5f}\")\n",
    "\n",
    "    mean_rmse = np.mean(cv_scores)\n",
    "    print(f\"  Trial Mean RMSE: {mean_rmse:.5f}\\n\")\n",
    "    return mean_rmse\n",
    "\n",
    "# --- Run Optuna Study ---\n",
    "N_TRIALS = 30 # For a serious competition, consider 50-100 trials\n",
    "print(f\"\\n--- Tuning Regressor with Optuna ({N_TRIALS} trials) using LEAK-FREE CV ---\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, X, y), n_trials=N_TRIALS)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "best_params_from_study = study.best_trial.params\n",
    "print(f\"  Value (RMSE): {study.best_value:.5f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params_from_study.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 4: FINAL MODEL TRAINING AND SUBMISSION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Training Final Model with Best Parameters on ALL Data ---\")\n",
    "\n",
    "# 1. Create user aggregates using the ENTIRE training dataset. This is correct\n",
    "# for the final model as it provides the most historical data for test predictions.\n",
    "final_user_aggregates = create_user_aggregates(X)\n",
    "\n",
    "# 2. Engineer features for the full train and test sets\n",
    "afe_final = AdvancedFeatureEngineering()\n",
    "X_train_eng_final = afe_final.fit_transform(X)\n",
    "X_test_eng_final = afe_final.transform(df_test)\n",
    "\n",
    "# 3. Merge aggregates into both sets\n",
    "X_train_final = pd.merge(X_train_eng_final, final_user_aggregates, on='userId', how='left').fillna(0)\n",
    "X_test_final = pd.merge(X_test_eng_final, final_user_aggregates, on='userId', how='left').fillna(0)\n",
    "\n",
    "# 4. Extract best parameters and build the final pipeline\n",
    "final_model_params = {k: v for k, v in best_params_from_study.items() if k not in ['smoothing']}\n",
    "final_smoothing = best_params_from_study.get('smoothing', 10)\n",
    "\n",
    "final_preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "    ('cat', TargetEncoder(columns=categorical_cols, smoothing=final_smoothing), categorical_cols)\n",
    "], remainder='drop', n_jobs=-1)\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', final_preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(**final_model_params, objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 5. Train on ALL available training data\n",
    "final_pipeline.fit(X_train_final, y)\n",
    "print(\"Final model trained successfully.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Generating Final Kaggle Submission ---\")\n",
    "# Align test columns with train columns to ensure consistency\n",
    "train_cols = X_train_final.columns\n",
    "X_test_final = X_test_final.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "# Predict log purchase value\n",
    "kaggle_log_preds = final_pipeline.predict(X_test_final)\n",
    "kaggle_log_preds[kaggle_log_preds < 0] = 0\n",
    "\n",
    "# Transform prediction back to original scale (inverse of log1p and scaling)\n",
    "kaggle_value_preds = np.expm1(kaggle_log_preds) * 1e6\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({'ID': df_test.index, 'purchaseValue': kaggle_value_preds})\n",
    "submission_df.to_csv('submission_robust_model11.csv', index=False)\n",
    "print(\"Submission file 'submission_robust_model.csv' created successfully.\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d73f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
