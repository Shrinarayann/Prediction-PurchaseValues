{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47af2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118b5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- File Paths -----------------------\n",
    "TRAIN_FILE_PATH ='/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/train_data.csv'\n",
    "TEST_FILE_PATH = '/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9c9b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Feature Engineering -------------------\n",
    "class AdvancedFeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['date'] = pd.to_datetime(X_copy['date'], errors='coerce', format='%Y%m%d')\n",
    "        X_copy['sessionYear'] = X_copy['date'].dt.year\n",
    "        X_copy['sessionMonth'] = X_copy['date'].dt.month\n",
    "        X_copy['sessionDayOfWeek'] = X_copy['date'].dt.dayofweek\n",
    "        X_copy['sessionHour'] = pd.to_datetime(X_copy['sessionStart'], unit='s').dt.hour\n",
    "        X_copy['is_weekend'] = (X_copy['sessionDayOfWeek'] >= 5).astype(int)\n",
    "        X_copy['month_day_interaction'] = X_copy['sessionMonth'].astype(str) + '_' + X_copy['sessionDayOfWeek'].astype(str)\n",
    "        X_copy['browser_os_interaction'] = X_copy['browser'].astype(str) + '_' + X_copy['os'].astype(str)\n",
    "        X_copy['geo_channel_interaction'] = X_copy['geoNetwork.continent'].astype(str) + '_' + X_copy['userChannel'].astype(str)\n",
    "        X_copy['device_channel_interaction'] = X_copy['deviceType'].astype(str) + '_' + X_copy['userChannel'].astype(str)\n",
    "        X_copy['hits_per_pageview'] = X_copy['totalHits'] / (X_copy['pageViews'] + 1e-6)\n",
    "        X_copy['ad_page_binned'] = X_copy['trafficSource.adwordsClickInfo.page'].apply(lambda p: 1 if p == 1.0 else (2 if pd.notna(p) else 0))\n",
    "        X_copy = X_copy.drop(columns=['date', 'sessionStart', 'sessionId', 'trafficSource.adwordsClickInfo.page'], errors='ignore')\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f92543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, smoothing=10):\n",
    "        self.columns, self.smoothing = columns, smoothing\n",
    "        self.mappings_, self.global_mean_ = {}, 0\n",
    "    def fit(self, X, y):\n",
    "        self.global_mean_ = np.mean(y)\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].fillna('missing')\n",
    "            agg = y.groupby(X[col]).agg(['mean', 'count'])\n",
    "            smooth_mean = (agg['count'] * agg['mean'] + self.smoothing * self.global_mean_) / (agg['count'] + self.smoothing)\n",
    "            self.mappings_[col] = smooth_mean.to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].fillna('missing').map(self.mappings_[col]).fillna(self.global_mean_)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e228da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- User-Level Features ------------------\n",
    "\n",
    "def create_user_level_features(df_train, df_test):\n",
    "    print(\"Creating user-level features...\")\n",
    "    df_train['purchaseValue'] = df_train['purchaseValue'].fillna(0) / 1e6\n",
    "    df_train['made_purchase'] = (df_train['purchaseValue'] > 0).astype(int)\n",
    "    combined_df = pd.concat([df_train.drop(['purchaseValue', 'made_purchase'], axis=1), df_test], axis=0)\n",
    "    user_agg = df_train.groupby('userId').agg(\n",
    "        user_session_count=('sessionId', 'nunique'),\n",
    "        user_total_hits=('totalHits', 'sum'),\n",
    "        user_avg_hits=('totalHits', 'mean'),\n",
    "        user_total_pageviews=('pageViews', 'sum'),\n",
    "        user_avg_pageviews=('pageViews', 'mean'),\n",
    "        user_purchase_count=('made_purchase', 'sum'),\n",
    "        user_total_purchase_value=('purchaseValue', 'sum'),\n",
    "    ).reset_index()\n",
    "    user_agg['user_conversion_rate'] = user_agg['user_purchase_count'] / user_agg['user_session_count']\n",
    "    user_agg['user_avg_purchase_value'] = user_agg['user_total_purchase_value'] / (user_agg['user_purchase_count'] + 1e-6)\n",
    "    df_train = pd.merge(df_train, user_agg, on='userId', how='left')\n",
    "    df_test = pd.merge(df_test, user_agg, on='userId', how='left')\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2157349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Creating user-level features...\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ Load Data ------------------------\n",
    "\n",
    "print(\"Loading and preparing data...\")\n",
    "df_train = pd.read_csv(TRAIN_FILE_PATH, dtype={'fullVisitorId': 'str'})\n",
    "df_test = pd.read_csv(TEST_FILE_PATH, dtype={'fullVisitorId': 'str'})\n",
    "one_value_cols = [col for col in df_train.columns if df_train[col].nunique(dropna=False) == 1]\n",
    "df_train = df_train.drop(columns=one_value_cols)\n",
    "df_test = df_test.drop(columns=[c for c in one_value_cols if c in df_test.columns], errors='ignore')\n",
    "df_train, df_test = create_user_level_features(df_train, df_test)\n",
    "df_train['log_purchaseValue'] = np.log1p(df_train['purchaseValue'])\n",
    "X = df_train.drop(columns=['purchaseValue', 'made_purchase', 'log_purchaseValue'])\n",
    "y = df_train['log_purchaseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10483f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Identify Columns --------------------\n",
    "\n",
    "X_engineered = AdvancedFeatureEngineering().fit_transform(X)\n",
    "user_level_numerical = [\n",
    "    'user_session_count', 'user_total_hits', 'user_avg_hits',\n",
    "    'user_total_pageviews', 'user_avg_pageviews', 'user_purchase_count',\n",
    "    'user_total_purchase_value', 'user_conversion_rate', 'user_avg_purchase_value'\n",
    "]\n",
    "session_level_numerical = ['sessionNumber', 'pageViews', 'totalHits', 'hits_per_pageview']\n",
    "numerical_cols = session_level_numerical + user_level_numerical\n",
    "categorical_cols = [col for col in X_engineered.columns if col not in numerical_cols and col != 'userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927ed6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Fixed Hyperparams --------------------\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 16,\n",
    "    'learning_rate': 0.0125,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf36448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Final XGBoost Regressor ---\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Train Final Model ---------------------\n",
    "\n",
    "print(\"\\n--- Training Final XGBoost Regressor ---\")\n",
    "final_pipeline = Pipeline([\n",
    "    ('engineering', AdvancedFeatureEngineering()),\n",
    "    ('preprocessing', ColumnTransformer([\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', RobustScaler())\n",
    "        ]), numerical_cols),\n",
    "        ('cat', TargetEncoder(columns=categorical_cols), categorical_cols)\n",
    "    ], remainder='drop')),\n",
    "    ('regressor', xgb.XGBRegressor(**xgb_params))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b75e623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained.\n"
     ]
    }
   ],
   "source": [
    "final_pipeline.fit(X, y)\n",
    "print(\"Final model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "561d2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation on Training Set ---\n",
      "RÂ² Score: 1.0000\n",
      "MAE: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Predict on training data\n",
    "train_preds_log = final_pipeline.predict(X)\n",
    "train_preds_real = np.expm1(train_preds_log)\n",
    "y_real = np.expm1(y)\n",
    "\n",
    "# Evaluation Metrics\n",
    "r2 = r2_score(y_real, train_preds_real)\n",
    "mae = mean_absolute_error(y_real, train_preds_real)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation on Training Set ---\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:,.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
