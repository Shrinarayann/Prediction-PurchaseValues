{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2951a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72bc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ==============================================================================\n",
    "# A: Custom Transformers (No changes here)\n",
    "# ==============================================================================\n",
    "class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
    "    # ... (code is correct)\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['date'] = pd.to_datetime(X_copy['date'], format='%Y%m%d')\n",
    "        X_copy['sessionYear'] = X_copy['date'].dt.year\n",
    "        X_copy['sessionMonth'] = X_copy['date'].dt.month\n",
    "        X_copy['sessionDayOfWeek'] = X_copy['date'].dt.dayofweek\n",
    "        X_copy['sessionHour'] = pd.to_datetime(X_copy['sessionStart'], unit='s').dt.hour\n",
    "        X_copy['ad_page_binned'] = X_copy['trafficSource.adwordsClickInfo.page'].apply(lambda p: 1 if p == 1.0 else (2 if pd.notna(p) else 0))\n",
    "        X_copy['gclIdPresent'] = (X_copy['gclIdPresent'] == 1).astype(int)\n",
    "        cols_to_drop = ['date', 'sessionStart', 'userId', 'sessionId', 'trafficSource.adwordsClickInfo.page']\n",
    "        X_copy = X_copy.drop(columns=cols_to_drop, errors='ignore')\n",
    "        return X_copy\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    # ... (code is correct)\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.mappings_ = {}\n",
    "        self.global_mean_ = 0\n",
    "    def fit(self, X, y):\n",
    "        X_fit = X.copy()\n",
    "        y_fit = y.copy()\n",
    "        self.global_mean_ = np.mean(y_fit)\n",
    "        for col in self.columns:\n",
    "            X_fit[col] = X_fit[col].fillna('missing')\n",
    "            mapping = y_fit.groupby(X_fit[col]).mean().to_dict()\n",
    "            self.mappings_[col] = mapping\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transform = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_transform[col] = X_transform[col].fillna('missing')\n",
    "            X_transform[col] = X_transform[col].map(self.mappings_[col]).fillna(self.global_mean_)\n",
    "        return X_transform\n",
    "\n",
    "# ==============================================================================\n",
    "# B: Load Data and Prepare Targets\n",
    "# ==============================================================================\n",
    "df = pd.read_csv('/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/train_data.csv')\n",
    "one_value_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=one_value_cols)\n",
    "df['purchaseValue'] = df['purchaseValue'] / 1e6\n",
    "df['made_purchase'] = (df['purchaseValue'] > 0).astype(int)\n",
    "df['log_purchaseValue'] = np.log1p(df['purchaseValue'])\n",
    "X = df.drop(columns=['purchaseValue', 'made_purchase', 'log_purchaseValue'])\n",
    "y = df[['purchaseValue', 'made_purchase', 'log_purchaseValue']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y['made_purchase'])\n",
    "\n",
    "# ==============================================================================\n",
    "# C: THE FIX - Apply Initial Engineering FIRST, then Define ColumnTransformer\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Apply the first-stage engineering to get the final set of columns\n",
    "feature_engineer = FeatureEngineeringTransformer()\n",
    "X_train_engineered = feature_engineer.fit_transform(X_train)\n",
    "X_test_engineered = feature_engineer.transform(X_test)\n",
    "\n",
    "# 2. NOW define the column lists based on the *engineered* data\n",
    "numerical_cols = ['sessionNumber', 'pageViews', 'totalHits', 'sessionYear', 'sessionMonth', 'sessionDayOfWeek', 'sessionHour']\n",
    "categorical_cols = [col for col in X_train_engineered.columns if col not in numerical_cols]\n",
    "\n",
    "# 3. Create the second-stage preprocessor (scaling and target encoding)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "        ('cat', TargetEncoder(columns=categorical_cols), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207876d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying initial feature engineering...\n",
      "Initial feature engineering complete.\n",
      "\n",
      "--- Building and Training Classifier ---\n",
      "Training Classifier Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrinarayan/Desktop/Prediction-PurchaseValues/venv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [20:09:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building and Training Regressor ---\n",
      "Training Regressor Model...\n",
      "\n",
      "--- Evaluating Final Combined Model ---\n",
      "\n",
      "Final RÂ² Score: 0.5553\n",
      "Final RMSE: $117.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# MODEL PIPELINING AND TRAINING\n",
    "# ==============================================================================\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 1: Apply Initial Feature Engineering (to create the final column set)\n",
    "# ==============================================================================\n",
    "print(\"Applying initial feature engineering...\")\n",
    "feature_engineer = FeatureEngineeringTransformer()\n",
    "X_train_engineered = feature_engineer.fit_transform(X_train)\n",
    "X_test_engineered = feature_engineer.transform(X_test)\n",
    "\n",
    "# Define column names based on the *engineered* data\n",
    "numerical_cols = ['sessionNumber', 'pageViews', 'totalHits', 'sessionYear', 'sessionMonth', 'sessionDayOfWeek', 'sessionHour']\n",
    "categorical_cols = [col for col in X_train_engineered.columns if col not in numerical_cols]\n",
    "\n",
    "print(\"Initial feature engineering complete.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 2: Define and Train the Classifier Component\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Building and Training Classifier ---\")\n",
    "\n",
    "# Define the preprocessor for the classifier\n",
    "clf_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "        ('cat', TargetEncoder(columns=categorical_cols), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit the preprocessor and transform the data\n",
    "clf_preprocessor.fit(X_train_engineered, y_train['made_purchase'])\n",
    "X_train_clf_processed = clf_preprocessor.transform(X_train_engineered)\n",
    "X_test_clf_processed = clf_preprocessor.transform(X_test_engineered)\n",
    "\n",
    "# Train the classifier model\n",
    "print(\"Training Classifier Model...\")\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
    "xgb_clf.fit(X_train_clf_processed, y_train['made_purchase'])\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 3: Define and Train the Regressor Component\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Building and Training Regressor ---\")\n",
    "\n",
    "# Define a NEW, SEPARATE preprocessor for the regressor\n",
    "reg_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numerical_cols),\n",
    "        ('cat', TargetEncoder(columns=categorical_cols), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit this preprocessor ONLY on the buyer data from the training set\n",
    "X_train_buyers_engineered = X_train_engineered[y_train['made_purchase'] == 1]\n",
    "y_train_buyers_log = y_train.loc[y_train['made_purchase'] == 1, 'log_purchaseValue']\n",
    "reg_preprocessor.fit(X_train_buyers_engineered, y_train_buyers_log)\n",
    "\n",
    "# Transform the necessary data sets\n",
    "# The model is trained on processed BUYER data\n",
    "X_train_buyers_reg_processed = reg_preprocessor.transform(X_train_buyers_engineered)\n",
    "# Predictions will be made on the full PROCESSED test set\n",
    "X_test_reg_processed = reg_preprocessor.transform(X_test_engineered)\n",
    "\n",
    "# Train the regressor model\n",
    "print(\"Training Regressor Model...\")\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse', random_state=42)\n",
    "xgb_reg.fit(X_train_buyers_reg_processed, y_train_buyers_log)\n",
    "\n",
    "# ==============================================================================\n",
    "# Step 4: Evaluate the Combined Model\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Evaluating Final Combined Model ---\")\n",
    "\n",
    "# Use the correctly processed test data for each model\n",
    "prob_purchase = xgb_clf.predict_proba(X_test_clf_processed)[:, 1]\n",
    "log_value_pred = xgb_reg.predict(X_test_reg_processed)\n",
    "\n",
    "# Combine and evaluate\n",
    "value_pred = np.expm1(log_value_pred)\n",
    "final_predictions = prob_purchase * value_pred\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "actual_values = y_test['purchaseValue']\n",
    "r2 = r2_score(actual_values, final_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(actual_values, final_predictions))\n",
    "\n",
    "print(f\"\\nFinal RÂ² Score: {r2:.4f}\")\n",
    "print(f\"Final RMSE: ${rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b95140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Kaggle Submission ---\n",
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Generating Kaggle Submission ---\")\n",
    "try:\n",
    "    # Load the test data from Kaggle.\n",
    "    kaggle_test_df = pd.read_csv('/Users/shrinarayan/Desktop/Prediction-PurchaseValues/dataset/test_data.csv') \n",
    "\n",
    "    kaggle_test_engineered = feature_engineer.transform(kaggle_test_df)\n",
    "\n",
    "\n",
    "    kaggle_test_clf_processed = clf_preprocessor.transform(kaggle_test_engineered)\n",
    "    kaggle_test_reg_processed = reg_preprocessor.transform(kaggle_test_engineered)\n",
    "    \n",
    "\n",
    "    kaggle_prob_purchase = xgb_clf.predict_proba(kaggle_test_clf_processed)[:, 1]\n",
    "    kaggle_log_value_pred = xgb_reg.predict(kaggle_test_reg_processed)\n",
    "    \n",
    "    \n",
    "    kaggle_pred_dollar_value = np.expm1(kaggle_log_value_pred)\n",
    "    kaggle_final_predictions = kaggle_prob_purchase * kaggle_pred_dollar_value\n",
    "    kaggle_final_predictions[kaggle_final_predictions < 0] = 0\n",
    "    \n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': kaggle_test_df.index,\n",
    "        'purchaseValue': kaggle_final_predictions\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"Submission file 'submission.csv' created successfully.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nKaggle 'test.csv' not found. Skipping submission file generation.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during submission generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c644d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
